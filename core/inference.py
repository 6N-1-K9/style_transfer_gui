import os
import torch
from .models import StyleGenerator
from utils.image_utils import preprocess_image, postprocess_image

class StyleTransferInference:
    def __init__(self, model_path, device='auto', log_callback=None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Å—Ç–∏–ª—è
        
        Args:
            model_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª–∏
            device: 'auto', 'cuda', –∏–ª–∏ 'cpu'
            log_callback: —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        if device == 'auto':
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.device = torch.device(device)
            
        self.model_path = model_path
        self.log_callback = log_callback or print
        self.model = None
        
        self._load_model()
    
    def _log(self, message):
        """–õ–æ–≥–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ"""
        self.log_callback(message)
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å"""
        try:
            self._log(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ {os.path.basename(self.model_path)}...")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            n_residual_blocks = 9  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            
            self.model = StyleGenerator(n_residual_blocks=n_residual_blocks).to(self.device)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
            checkpoint = torch.load(self.model_path, map_location=self.device)
            self.model.load_state_dict(checkpoint)
            self.model.eval()
            
            self._log("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
        except Exception as e:
            self._log(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise
    
    def transfer_style(self, image_path, image_size=256):
        """
        –ü—Ä–∏–º–µ–Ω—è–µ—Ç —Å—Ç–∏–ª—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
        
        Args:
            image_path: –ø—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            image_size: —Ä–∞–∑–º–µ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            
        Returns:
            PIL.Image –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        """
        try:
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
            image_tensor, original_size, original_image = preprocess_image(
                image_path, image_size, self.device
            )
            
            if image_tensor is None:
                return None
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç–∏–ª—å
            with torch.no_grad():
                styled_tensor = self.model(image_tensor)
            
            # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
            styled_image = postprocess_image(styled_tensor, original_size)
            
            return styled_image
            
        except Exception as e:
            self._log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Å—Ç–∏–ª—è –∫ {os.path.basename(image_path)}: {e}")
            return None
    
    def transfer_style_batch(self, image_paths, image_size=256):
        """
        –ü—Ä–∏–º–µ–Ω—è–µ—Ç —Å—Ç–∏–ª—å –∫ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
        
        Args:
            image_paths: —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
            image_size: —Ä–∞–∑–º–µ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            
        Returns:
            dict: {–ø—É—Ç—å_–∫_—Ñ–∞–π–ª—É: PIL.Image}
        """
        results = {}
        
        for image_path in image_paths:
            styled_image = self.transfer_style(image_path, image_size)
            if styled_image:
                results[image_path] = styled_image
        
        return results